{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeDinhNhutTien/Machine_Learning_20130433/blob/main/Lab_6_20130433_LeDinhNhutTien.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Na√Øve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "X = mnist.data\n",
        "y = mnist.target\n",
        "#Chuan hoa du lieu\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Split 7-3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "#Random forest\n",
        "clf_randomforest=RandomForestClassifier(n_estimators=100)\n",
        "clf_randomforest.fit(X_train,y_train)\n",
        "y_pred_random = clf_randomforest.predict(X_test)\n",
        "#NaiveBayes\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_bayes = model.predict(X_test)\n",
        "#SVM with \n",
        "clf_linear = svm.SVC(kernel='linear')\n",
        "clf_linear.fit(X_train, y_train)\n",
        "y_pred_linear = clf_linear.predict(X_test)\n",
        "table = {\n",
        "    \"Random forest\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_random),\n",
        "        \"precision\": precision_score(y_test, y_pred_random, average='macro'),\n",
        "        \"recall\": recall_score(y_test, y_pred_random, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_random, average='macro')\n",
        "    },\n",
        "    \"NaiveBayes\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_bayes),\n",
        "        \"precision\": precision_score(y_test, y_pred_bayes, average='macro'),\n",
        "        \"recall\": recall_score(y_test, y_pred_bayes, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_bayes, average='macro')\n",
        "    },\n",
        "    \"SVM linear\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_linear),\n",
        "        \"precision\": precision_score(y_test, y_pred_linear, average='macro'),\n",
        "        \"recall\": recall_score(y_test, y_pred_linear, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_linear, average='macro')\n",
        "    }\n",
        "}\n",
        "#print\n",
        "df_metrics = pd.DataFrame.from_dict(table, orient='index')\n",
        "print(df_metrics)"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45e46e2-c27b-44cc-d00b-8d24cadf07bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               accuracy  precision    recall        f1\n",
            "Random forest  0.974074   0.973578  0.973938  0.973617\n",
            "NaiveBayes     0.787037   0.823782  0.782850  0.776377\n",
            "SVM linear     0.977778   0.977356  0.978005  0.977647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importances\n",
        "importances = clf_randomforest.feature_importances_\n",
        "#sort\n",
        "sorted_idx = np.argsort(importances)[::-1]\n",
        "\n",
        "for idx in sorted_idx:\n",
        "    print(f\"{mnist.feature_names[idx]}: {importances[idx]}\")\n",
        "     \n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5BaxOb-vMqP",
        "outputId": "c4384497-d16e-4d3b-befd-811fb4ff6791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel_2_5: 0.04367820327880653\n",
            "pixel_5_3: 0.04178494202269395\n",
            "pixel_3_2: 0.041150418478765355\n",
            "pixel_4_4: 0.03990858144549604\n",
            "pixel_5_2: 0.0386142005550112\n",
            "pixel_3_4: 0.03394578653409461\n",
            "pixel_7_5: 0.03372782352917873\n",
            "pixel_2_4: 0.032623036805608185\n",
            "pixel_1_2: 0.03125487912029425\n",
            "pixel_3_6: 0.031186151003436472\n",
            "pixel_4_1: 0.030256912092483587\n",
            "pixel_3_3: 0.027649011862027093\n",
            "pixel_4_2: 0.02742491626535327\n",
            "pixel_0_2: 0.02654250338383485\n",
            "pixel_1_5: 0.025787417344720863\n",
            "pixel_7_4: 0.0247087181143684\n",
            "pixel_3_5: 0.024281126639127532\n",
            "pixel_6_3: 0.024056270556447622\n",
            "pixel_4_6: 0.02382604800791366\n",
            "pixel_6_6: 0.02278684370328175\n",
            "pixel_2_3: 0.021683550062163475\n",
            "pixel_5_6: 0.021135231253828754\n",
            "pixel_2_2: 0.021123874451593524\n",
            "pixel_7_2: 0.020868612404048026\n",
            "pixel_4_5: 0.020356492033333513\n",
            "pixel_5_4: 0.020186376346883538\n",
            "pixel_7_6: 0.019860815463766657\n",
            "pixel_6_2: 0.019275225581639178\n",
            "pixel_0_5: 0.01878342469720338\n",
            "pixel_6_5: 0.018479830420495183\n",
            "pixel_5_5: 0.01712750740993671\n",
            "pixel_4_3: 0.017080153384993305\n",
            "pixel_1_4: 0.01631481928790854\n",
            "pixel_3_1: 0.012602227078052157\n",
            "pixel_6_4: 0.012551432173121262\n",
            "pixel_1_1: 0.010998148262527574\n",
            "pixel_7_3: 0.010258921345919629\n",
            "pixel_0_3: 0.009959061587621996\n",
            "pixel_0_4: 0.008895943584047685\n",
            "pixel_0_6: 0.008534244716916831\n",
            "pixel_2_6: 0.008152230333794527\n",
            "pixel_5_1: 0.008044315835276898\n",
            "pixel_1_3: 0.007549761715237393\n",
            "pixel_2_1: 0.006778390897847082\n",
            "pixel_1_6: 0.005804533782675273\n",
            "pixel_7_7: 0.0026607048662237063\n",
            "pixel_7_1: 0.002581773395826649\n",
            "pixel_6_1: 0.0019512735738978543\n",
            "pixel_0_1: 0.0019164621054382374\n",
            "pixel_6_7: 0.0015014566307592792\n",
            "pixel_1_7: 0.0007478599728773041\n",
            "pixel_0_7: 0.0006340137042560517\n",
            "pixel_2_7: 0.00015370747451547403\n",
            "pixel_2_0: 8.621690189918861e-05\n",
            "pixel_3_7: 7.963417927038391e-05\n",
            "pixel_6_0: 4.042481739598454e-05\n",
            "pixel_5_7: 1.7485621368599114e-05\n",
            "pixel_5_0: 1.5921715767888887e-05\n",
            "pixel_7_0: 1.4150186727304958e-05\n",
            "pixel_1_0: 0.0\n",
            "pixel_3_0: 0.0\n",
            "pixel_4_0: 0.0\n",
            "pixel_4_7: 0.0\n",
            "pixel_0_0: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/Machine_Learning'\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTZJI2CNv8I-",
        "outputId": "c965ccdf-d5c0-450d-8afa-d6fd0dc20511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Machine_Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataSet = pd.read_csv(\"bank.csv\")\n",
        "print(dataSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OfDqHnowZo3",
        "outputId": "6a79645e-75ac-48a8-de53-bd051a6e0cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       age          job  marital  education default  balance housing loan  \\\n",
            "0       59       admin.  married  secondary      no     2343     yes   no   \n",
            "1       56       admin.  married  secondary      no       45      no   no   \n",
            "2       41   technician  married  secondary      no     1270     yes   no   \n",
            "3       55     services  married  secondary      no     2476     yes   no   \n",
            "4       54       admin.  married   tertiary      no      184      no   no   \n",
            "...    ...          ...      ...        ...     ...      ...     ...  ...   \n",
            "11157   33  blue-collar   single    primary      no        1     yes   no   \n",
            "11158   39     services  married  secondary      no      733      no   no   \n",
            "11159   32   technician   single  secondary      no       29      no   no   \n",
            "11160   43   technician  married  secondary      no        0      no  yes   \n",
            "11161   34   technician  married  secondary      no        0      no   no   \n",
            "\n",
            "        contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
            "0       unknown    5   may      1042         1     -1         0  unknown   \n",
            "1       unknown    5   may      1467         1     -1         0  unknown   \n",
            "2       unknown    5   may      1389         1     -1         0  unknown   \n",
            "3       unknown    5   may       579         1     -1         0  unknown   \n",
            "4       unknown    5   may       673         2     -1         0  unknown   \n",
            "...         ...  ...   ...       ...       ...    ...       ...      ...   \n",
            "11157  cellular   20   apr       257         1     -1         0  unknown   \n",
            "11158   unknown   16   jun        83         4     -1         0  unknown   \n",
            "11159  cellular   19   aug       156         2     -1         0  unknown   \n",
            "11160  cellular    8   may         9         2    172         5  failure   \n",
            "11161  cellular    9   jul       628         1     -1         0  unknown   \n",
            "\n",
            "      deposit  \n",
            "0         yes  \n",
            "1         yes  \n",
            "2         yes  \n",
            "3         yes  \n",
            "4         yes  \n",
            "...       ...  \n",
            "11157      no  \n",
            "11158      no  \n",
            "11159      no  \n",
            "11160      no  \n",
            "11161      no  \n",
            "\n",
            "[11162 rows x 17 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ],
      "metadata": {
        "id": "q89LEvT7dqaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "dataSet[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']] = scaler.fit_transform(dataSet[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']])\n",
        "print(dataSet[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']])"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3f2b97-4689-46d5-dc98-65d8c0624191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age   balance       day  campaign     pdays  previous\n",
            "0      1.491505  0.252525 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "1      1.239676 -0.459974 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "2     -0.019470 -0.080160 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "3      1.155733  0.293762 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "4      1.071790 -0.416876 -1.265746 -0.186785 -0.481184 -0.363260\n",
            "...         ...       ...       ...       ...       ...       ...\n",
            "11157 -0.691015 -0.473616  0.515650 -0.554168 -0.481184 -0.363260\n",
            "11158 -0.187357 -0.246658  0.040612  0.547981 -0.481184 -0.363260\n",
            "11159 -0.774958 -0.464934  0.396891 -0.186785 -0.481184 -0.363260\n",
            "11160  0.148416 -0.473926 -0.909466 -0.186785  1.109571  1.818332\n",
            "11161 -0.607072 -0.473926 -0.790707 -0.554168 -0.481184 -0.363260\n",
            "\n",
            "[11162 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ],
      "metadata": {
        "id": "r7acR0TxdvY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encode_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "onehotencoder = OneHotEncoder()\n",
        "onehotencoder.fit(dataSet[encode_cols])\n",
        "onehot_encoded = onehotencoder.transform(dataSet[encode_cols]).toarray()\n",
        "onehot_encoded_df = pd.DataFrame(onehot_encoded, columns=onehotencoder.get_feature_names_out(encode_cols))\n",
        "dataSet = pd.concat([dataSet, onehot_encoded_df], axis=1)\n",
        "dataSet = dataSet.drop(encode_cols, axis=1)\n",
        "print(dataSet.columns)"
      ],
      "metadata": {
        "id": "egtgBmAtd0um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9c4960-1b6d-4afc-ab42-119e4b9f5498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
            "       'deposit', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
            "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
            "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
            "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
            "       'education_primary', 'education_secondary', 'education_tertiary',\n",
            "       'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
            "       'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
            "       'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
            "       'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
            "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
            "       'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
            "       'poutcome_unknown'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, Na√ØveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ],
      "metadata": {
        "id": "K2Si6d69d1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split 7-3\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataSet.drop('deposit', axis=1), dataSet['deposit'], test_size=0.3, random_state=42)\n",
        "#Decision Tree\n",
        "tree = DecisionTreeClassifier(criterion=\"gini\", random_state=42, max_depth=5, min_samples_leaf=10)\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "#Random forest\n",
        "clf_randomforest=RandomForestClassifier(n_estimators=100)\n",
        "clf_randomforest.fit(X_train,y_train)\n",
        "y_pred_random = clf_randomforest.predict(X_test)\n",
        "#kNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "#NaiveBayes\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_bayes = model.predict(X_test)\n",
        "table = {\n",
        "    \"Decision Tree\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_tree),\n",
        "        \"precision\": precision_score(y_test, y_pred_tree, average='macro',zero_division=1),\n",
        "        \"recall\": recall_score(y_test, y_pred_tree, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_tree, average='macro')\n",
        "    },\n",
        "    \"Random forest\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_random),\n",
        "        \"precision\": precision_score(y_test, y_pred_random, average='macro',zero_division=1),\n",
        "        \"recall\": recall_score(y_test, y_pred_random, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_random, average='macro')\n",
        "    },\n",
        "    \"KNN\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_knn),\n",
        "        \"precision\": precision_score(y_test, y_pred_knn, average='macro',zero_division=1),\n",
        "        \"recall\": recall_score(y_test, y_pred_knn, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_knn, average='macro')\n",
        "    },\n",
        "    \"NaiveBayes\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_bayes),\n",
        "        \"precision\": precision_score(y_test, y_pred_bayes, average='macro',zero_division=1),\n",
        "        \"recall\": recall_score(y_test, y_pred_bayes, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_bayes, average='macro')\n",
        "    },  \n",
        "}\n",
        "#print\n",
        "df_metrics = pd.DataFrame.from_dict(table, orient='index')\n",
        "print(df_metrics)"
      ],
      "metadata": {
        "id": "Ouil-cf_d8jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9583e0d-7621-4830-a5f5-da15e24fdecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               accuracy  precision    recall        f1\n",
            "Decision Tree  0.789788   0.791646  0.787806  0.788402\n",
            "Random forest  0.843834   0.844258  0.844725  0.843812\n",
            "KNN            0.769782   0.769419  0.769323  0.769367\n",
            "NaiveBayes     0.723500   0.739052  0.717793  0.715221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ],
      "metadata": {
        "id": "SweVRB4meApP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = clf_randomforest.feature_importances_\n",
        "#sort\n",
        "sorted_idx = np.argsort(importances)[::-1]\n",
        "#print rank\n",
        "for idx in sorted_idx:\n",
        "    print(f\"{importances[idx]}\")"
      ],
      "metadata": {
        "id": "seFBhqCSeC7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9d5325-ef92-4a00-d4b9-f6b2c70732bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04367820327880653\n",
            "0.04178494202269395\n",
            "0.041150418478765355\n",
            "0.03990858144549604\n",
            "0.0386142005550112\n",
            "0.03394578653409461\n",
            "0.03372782352917873\n",
            "0.032623036805608185\n",
            "0.03125487912029425\n",
            "0.031186151003436472\n",
            "0.030256912092483587\n",
            "0.027649011862027093\n",
            "0.02742491626535327\n",
            "0.02654250338383485\n",
            "0.025787417344720863\n",
            "0.0247087181143684\n",
            "0.024281126639127532\n",
            "0.024056270556447622\n",
            "0.02382604800791366\n",
            "0.02278684370328175\n",
            "0.021683550062163475\n",
            "0.021135231253828754\n",
            "0.021123874451593524\n",
            "0.020868612404048026\n",
            "0.020356492033333513\n",
            "0.020186376346883538\n",
            "0.019860815463766657\n",
            "0.019275225581639178\n",
            "0.01878342469720338\n",
            "0.018479830420495183\n",
            "0.01712750740993671\n",
            "0.017080153384993305\n",
            "0.01631481928790854\n",
            "0.012602227078052157\n",
            "0.012551432173121262\n",
            "0.010998148262527574\n",
            "0.010258921345919629\n",
            "0.009959061587621996\n",
            "0.008895943584047685\n",
            "0.008534244716916831\n",
            "0.008152230333794527\n",
            "0.008044315835276898\n",
            "0.007549761715237393\n",
            "0.006778390897847082\n",
            "0.005804533782675273\n",
            "0.0026607048662237063\n",
            "0.002581773395826649\n",
            "0.0019512735738978543\n",
            "0.0019164621054382374\n",
            "0.0015014566307592792\n",
            "0.0007478599728773041\n",
            "0.0006340137042560517\n",
            "0.00015370747451547403\n",
            "8.621690189918861e-05\n",
            "7.963417927038391e-05\n",
            "4.042481739598454e-05\n",
            "1.7485621368599114e-05\n",
            "1.5921715767888887e-05\n",
            "1.4150186727304958e-05\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and thencompare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "\n",
        "dataSet = pd.read_csv(\"creditcard.csv\")"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataSet.drop('Class', axis=1)\n",
        "y = dataSet['Class']\n",
        "#Chuan hoa du lieu\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Split 7-3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "#Decision Tree\n",
        "tree = DecisionTreeClassifier(criterion=\"gini\", random_state=42, max_depth=3, min_samples_leaf=5)\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "#Knn\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "#Logistic Regression\n",
        "logistic = LogisticRegression(max_iter=1000)\n",
        "logistic.fit(X_train, y_train)\n",
        "y_pred_logistic = logistic.predict(X_test)\n",
        "#Polynomial Kernel\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_polynomial = clf.predict(X_test)\n",
        "#Random forest\n",
        "clf_randomforest=RandomForestClassifier(n_estimators=100)\n",
        "clf_randomforest.fit(X_train,y_train)\n",
        "y_pred_random = clf_randomforest.predict(X_test)\n",
        "#NaiveBayes\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_bayes = model.predict(X_test)\n",
        "#Create table\n",
        "table = {\n",
        "    \"Tree\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_tree),\n",
        "        \"precision\": precision_score(y_test, y_pred_tree, average='macro'),\n",
        "        \"recall\": recall_score(y_test, y_pred_tree, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_tree, average='macro')\n",
        "    },\n",
        "     \"KNN\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_knn),\n",
        "        \"precision\": precision_score(y_test, y_pred_knn, average='macro'),\n",
        "        \"recall\": recall_score(y_test, y_pred_knn, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_knn, average='macro')\n",
        "    },\n",
        "    \"Logistic\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_logistic),\n",
        "        \"precision\": precision_score(y_test, y_pred_logistic, average='macro'),\n",
        "        \"recall\": recall_score(y_test, y_pred_logistic, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_logistic, average='macro')\n",
        "    },\n",
        "    \"Polynomial Kernel\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_polynomial),\n",
        "        \"precision\": precision_score(y_test, y_pred_polynomial, average='macro'),\n",
        "        \"recall\": recall_score(y_test, y_pred_polynomial, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_polynomial, average='macro')\n",
        "    },\n",
        "    \"Random forest\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_random),\n",
        "        \"precision\": precision_score(y_test, y_pred_random, average='macro',zero_division=1),\n",
        "        \"recall\": recall_score(y_test, y_pred_random, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_random, average='macro')\n",
        "    },\n",
        "    \"NaiveBayes\":{\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_bayes),\n",
        "        \"precision\": precision_score(y_test, y_pred_bayes, average='macro',zero_division=1),\n",
        "        \"recall\": recall_score(y_test, y_pred_bayes, average='macro'),\n",
        "        \"f1\": f1_score(y_test, y_pred_bayes, average='macro')\n",
        "    }\n",
        "}\n",
        "\n",
        "df_metrics = pd.DataFrame.from_dict(table, orient='index')\n",
        "print(df_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d-5RbK-yuO2",
        "outputId": "88d0576f-ebe7-471a-ec6f-ef8f3afaf222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   accuracy  precision    recall        f1\n",
            "Logistic           0.999274   0.938483  0.816106  0.867340\n",
            "KNN                0.999415   0.928973  0.878577  0.902197\n",
            "Tree               0.999368   0.929602  0.860200  0.891842\n",
            "Polynomial Kernel  0.999485   0.948088  0.882283  0.912569\n",
            "Random forest      0.999614   0.969933  0.904371  0.934686\n",
            "NaiveBayes         0.978044   0.529062  0.911922  0.549048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}